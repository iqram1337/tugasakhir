{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import time\n",
    "from util import (\n",
    "    load_GaMMA_catalog,\n",
    "    load_scsn,\n",
    "    load_Ross2019,\n",
    "    load_Shelly2020,\n",
    "    load_Liu2020,\n",
    "    load_eqnet_catalog,\n",
    "    filter_catalog,\n",
    "    calc_detection_performance,\n",
    "    calc_time_loc_error,\n",
    "    plot_loc_error,\n",
    "    timestamp,\n",
    "    calc_time_mag_error,\n",
    ")\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates =[f\"2019-07-{x:02d}\" for x in range(4, 11)]\n",
    "start_datetime = datetime.fromisoformat(dates[0])\n",
    "end_datetime = datetime.fromisoformat(dates[-1])\n",
    "hours = range(24)\n",
    "xmin = 0\n",
    "xmax = 111.2\n",
    "ymin = xmin\n",
    "ymax = xmax\n",
    "\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = lambda x: os.path.join(\"./\", x)\n",
    "\n",
    "## read picks\n",
    "picks_file = \"picks_gamma.csv\"\n",
    "picks = pd.read_csv(root_dir(picks_file), delimiter=\"\\t\")\n",
    "picks[\"time\"] = picks[\"timestamp\"].apply(lambda x: datetime.fromisoformat(x))\n",
    "\n",
    "## read stations\n",
    "stations = pd.read_csv(root_dir(\"stations.csv\"), delimiter=\"\\t\")\n",
    "\n",
    "## read official catalogs\n",
    "# baseline_catalog = pd.read_csv(root_dir(\"events.csv\"), delimiter=\"\\t\")\n",
    "# baseline_catalog[\"time\"] = baseline_catalog[\"time\"].apply(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%f\"))\n",
    "\n",
    "# ## read config\n",
    "# with open(root_dir(\"config.pkl\"), \"r\") as fp:\n",
    "#     config = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered catalog 2019-07-04 00:00:00-2019-07-10 00:00:00: 1475 events\n",
      "Filtered catalog 2019-07-04 00:00:00-2019-07-10 00:00:00: 11520 events\n",
      "Filtered catalog 2019-07-04 00:00:00-2019-07-10 00:00:00: 29384 events\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('int32'), dtype('<U1')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m t_scsn, xyz_scsn, mag_scsn, catalog_scsn \u001b[38;5;241m=\u001b[39m filter_catalog(load_scsn(), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n\u001b[0;32m      6\u001b[0m t_ross2019, xyz_ross2019, mag_ross2019, catalog_ross2019 \u001b[38;5;241m=\u001b[39m filter_catalog(load_Ross2019(), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n\u001b[1;32m----> 7\u001b[0m t_liu2020, xyz_liu2020, mag_liu2020, catalog_liu2020 \u001b[38;5;241m=\u001b[39m filter_catalog(\u001b[43mload_Liu2020\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n\u001b[0;32m      8\u001b[0m t_shelly2020, xyz_shelly2020, mag_shelly2020, catalog_shelly2020 \u001b[38;5;241m=\u001b[39m filter_catalog(load_Shelly2020(), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n",
      "File \u001b[1;32mD:\\QuakeFlow\\GaMMA\\tests\\util.py:244\u001b[0m, in \u001b[0;36mload_Liu2020\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    220\u001b[0m     os\u001b[38;5;241m.\u001b[39msystem(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwget -O Liu2020.txt https://agupubs.onlinelibrary.wiley.com/action/downloadSupplement\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m?doi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m=10.1029\u001b[39m\u001b[38;5;132;01m%2F\u001b[39;00m\u001b[38;5;124m2019GL086189\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m&file\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m=grl60250-sup-0002-2019GL086189-ts01.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m     )\n\u001b[0;32m    224\u001b[0m catalog \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiu2020.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m     sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     },\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    243\u001b[0m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 244\u001b[0m     \u001b[43mcatalog\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{:04d}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;241m+\u001b[39m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:02d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;241m+\u001b[39m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:02d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;241m+\u001b[39m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:02d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;241m+\u001b[39m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:02d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;241m+\u001b[39m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msec\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:06.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    255\u001b[0m )\n\u001b[0;32m    256\u001b[0m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(datetime\u001b[38;5;241m.\u001b[39mfromisoformat)\n\u001b[0;32m    257\u001b[0m catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m (config\u001b[38;5;241m.\u001b[39mcenter[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m config\u001b[38;5;241m.\u001b[39mhorizontal)) \u001b[38;5;241m*\u001b[39m config\u001b[38;5;241m.\u001b[39mdegree2km\n",
      "File \u001b[1;32mD:\\miniconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py:5819\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   5818\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniconda3\\lib\\site-packages\\pandas\\core\\base.py:1381\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mD:\\miniconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:285\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    281\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mD:\\miniconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:220\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    217\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    223\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    224\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('int32'), dtype('<U1')) -> None"
     ]
    }
   ],
   "source": [
    "## read catalaogs\n",
    "t_gamma, xyz_gamma, mag_gamma, catalog_gamma = filter_catalog(load_GaMMA_catalog(root_dir(\"catalog_gamma.csv\")), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n",
    "catalog_gamma[\"time\"] = catalog_gamma[\"time\"].apply(lambda x: datetime.fromisoformat(x))\n",
    "# t_eqnet, xyz_eqnet, mag_eqnet, catalog_eqnet = filter_catalog(load_eqnet_catalog(root_dir(\"2019-07-04-2019-07-08-threshold050.txt\")), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n",
    "t_scsn, xyz_scsn, mag_scsn, catalog_scsn = filter_catalog(load_scsn(), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n",
    "t_ross2019, xyz_ross2019, mag_ross2019, catalog_ross2019 = filter_catalog(load_Ross2019(), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n",
    "t_liu2020, xyz_liu2020, mag_liu2020, catalog_liu2020 = filter_catalog(load_Liu2020(), start_datetime, end_datetime, xmin, xmax, ymin, ymax)\n",
    "t_shelly2020, xyz_shelly2020, mag_shelly2020, catalog_shelly2020 = filter_catalog(load_Shelly2020(), start_datetime, end_datetime, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model=\"GaMMA\"\n",
    "label_baseline=\"SCSN\"\n",
    "catalog_model = catalog_gamma\n",
    "catalog_baseline = catalog_scsn\n",
    "marker_size = 0.2\n",
    "bins = min(len(catalog_baseline[\"time\"])//50 + 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(mag_gamma, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], label=f\"GaMMA\\n:{len(mag_gamma)}\")\n",
    "plt.hist(mag_scsn, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], alpha=0.5, label=f\"SCSN: {len(mag_scsn)}\")\n",
    "plt.gca().set_yscale('log')\n",
    "ylim = plt.ylim()\n",
    "plt.legend()\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(mag_ross2019, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], label=f\"Ross et al. (2019)\\n:{len(mag_ross2019)}\")\n",
    "plt.hist(mag_scsn, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], alpha=0.5, label=f\"SCSN: {len(mag_scsn)}\")\n",
    "plt.gca().set_yscale('log')\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(mag_liu2020, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], label=f\"Liu et al. (2020)\\n:{len(mag_liu2020)}\")\n",
    "plt.hist(mag_scsn, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], alpha=0.5, label=f\"SCSN: {len(mag_scsn)}\")\n",
    "plt.gca().set_yscale('log')\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(mag_shelly2020, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], label=f\"Shelly (2020)\\n:{len(mag_shelly2020)}\")\n",
    "plt.hist(mag_scsn, bins=50, range=[np.min([np.min(mag_gamma), np.min(mag_scsn)]), np.max([np.max(mag_gamma), np.max(mag_scsn)])], alpha=0.5,  label=f\"SCSN: {len(mag_scsn)}\")\n",
    "plt.gca().set_yscale('log')\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/compare_magnitude.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(\"figures/compare_magnitude.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GaMMA\n",
    "marker_size = 0.4\n",
    "alpha = 0.4\n",
    "plot_depth = True\n",
    "\n",
    "## EQNet\n",
    "# marker_size = 0.8\n",
    "# alpha = 0.4\n",
    "# plot_depth = False\n",
    "\n",
    "fig = plt.figure(figsize=plt.rcParams[\"figure.figsize\"]*np.array([1.8,1.3]))\n",
    "box = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "text_loc = [0.05, 0.92]\n",
    "if plot_depth:\n",
    "    grd = fig.add_gridspec(ncols=2, nrows=2, width_ratios=[1.5, 1], height_ratios=[1,1])\n",
    "    fig.add_subplot(grd[:, 0])\n",
    "plt.scatter(catalog_baseline[\"longitude\"], catalog_baseline[\"latitude\"], s=marker_size, c=\"C1\", linewidths=marker_size, alpha=0.5, rasterized=True)\n",
    "plt.scatter(catalog_model[\"longitude\"], catalog_model[\"latitude\"], s=marker_size, c=\"C0\", linewidths=marker_size, alpha=alpha, rasterized=True)\n",
    "plt.plot(stations[\"longitude\"], stations[\"latitude\"], 'k^', markersize=5, alpha=1.0, label=\"Stations\")\n",
    "plt.axis(\"scaled\")\n",
    "plt.xlim(np.array(config[\"xlim_degree\"]))#+np.array([0.2,-0.27]))\n",
    "plt.ylim(np.array(config[\"ylim_degree\"]))#+np.array([0.2,-0.27]))\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.gca().set_prop_cycle(None)\n",
    "plt.plot(config[\"xlim_degree\"][0]-10, config[\"ylim_degree\"][0]-10, '.', c=\"C0\", markersize=10, label=f\"{label_model}: {len(catalog_model['time'])}\")\n",
    "plt.plot(config[\"xlim_degree\"][0]-10, config[\"ylim_degree\"][0]-10, '.', c=\"C1\", markersize=10, label=f\"{label_baseline}: {len(catalog_baseline['time'])}\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "if plot_depth:\n",
    "    plt.text(text_loc[0], text_loc[1]+0.03, '(i)', horizontalalignment='left', verticalalignment=\"top\", \n",
    "            transform=plt.gca().transAxes, fontweight=\"normal\", bbox=box)\n",
    "\n",
    "if plot_depth:\n",
    "    fig.add_subplot(grd[0, 1])\n",
    "    plt.scatter(catalog_baseline[\"longitude\"], catalog_baseline[\"depth(m)\"]/1e3, s=marker_size, c=\"C1\", linewidths=marker_size, alpha=0.5, rasterized=True)\n",
    "    plt.scatter(catalog_model[\"longitude\"], catalog_model[\"depth(m)\"]/1e3, s=marker_size, c=\"C0\", linewidths=marker_size, alpha=alpha, rasterized=True)\n",
    "    # plt.axis(\"scaled\")\n",
    "    plt.xlim(np.array(config[\"xlim_degree\"]))#+np.array([0.2,-0.27]))\n",
    "    plt.ylim([0,21])\n",
    "    # plt.ylim(bottom=0, top=41)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Depth (km)\")\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.plot(config[\"xlim_degree\"][0]-10, 31, '.', c=\"C0\", markersize=10, label=f\"{label_model}\")\n",
    "    plt.plot(31, 31, '.', c=\"C1\", markersize=10, label=f\"{label_baseline}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.text(text_loc[0], text_loc[1], '(ii)', horizontalalignment='left', verticalalignment=\"top\", \n",
    "            transform=plt.gca().transAxes, fontweight=\"normal\", bbox=box)\n",
    "\n",
    "    fig.add_subplot(grd[1, 1])\n",
    "    plt.scatter(catalog_baseline[\"latitude\"], catalog_baseline[\"depth(m)\"]/1e3, s=marker_size, c=\"C1\", linewidths=marker_size, alpha=0.5, rasterized=True)\n",
    "    plt.scatter(catalog_model[\"latitude\"], catalog_model[\"depth(m)\"]/1e3, s=marker_size, c=\"C0\", linewidths=marker_size, alpha=alpha, rasterized=True)\n",
    "    # plt.axis(\"scaled\")\n",
    "    plt.xlim(np.array(config[\"ylim_degree\"]))#+np.array([0.2,-0.27]))\n",
    "    plt.ylim([0,21])\n",
    "    # plt.ylim(bottom=0, top=41)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Latitude\")\n",
    "    plt.ylabel(\"Depth (km)\")\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.plot(config[\"ylim_degree\"][0]-10, 31, '.', c=\"C0\", markersize=10, label=f\"{label_model}\")\n",
    "    plt.plot(31, 31, '.', c=\"C1\", markersize=10, label=f\"{label_baseline}\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.tight_layout()\n",
    "    plt.text(text_loc[0], text_loc[1], '(iii)', horizontalalignment='left', verticalalignment=\"top\", \n",
    "            transform=plt.gca().transAxes, fontweight=\"normal\", bbox=box)\n",
    "\n",
    "plt.savefig(root_dir(\"figures/earthquake_location.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(root_dir(\"figures/earthquake_location.pdf\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np.array(catalog_model[\"time\"]).astype(\"datetime64[ms]\"), range=(config[\"starttime\"], config[\"endtime\"]), bins=bins, label=f\"{label_model}: {len(catalog_model['time'])}\")\n",
    "plt.hist(np.array(catalog_baseline[\"time\"]).astype(\"datetime64[ms]\"), range=(config[\"starttime\"], config[\"endtime\"]), bins=bins, label=f\"{label_baseline}: {len(catalog_baseline['time'])}\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Date\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.gca().autoscale(enable=True, axis='x', tight=True)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(root_dir(\"figures/earthquake_number.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(root_dir(\"figures/earthquake_number.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np.array(catalog_shelly2020[\"time\"]).astype(\"datetime64[ms]\"), range=(config[\"starttime\"], config[\"endtime\"]), bins=bins, label=f\"Shelly (2020): {len(catalog_shelly2020['time'])}\")\n",
    "plt.hist(np.array(catalog_baseline[\"time\"]).astype(\"datetime64[ms]\"), range=(config[\"starttime\"], config[\"endtime\"]), bins=bins, alpha=0.6, label=f\"{label_baseline}: {len(catalog_baseline['time'])}\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Date\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.gca().autoscale(enable=True, axis='x', tight=True)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.legend()\n",
    "plt.savefig(root_dir(\"figures/earthquake_number_shelly.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(root_dir(\"figures/earthquake_number_shelly.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np.array(catalog_liu2020[\"time\"]).astype(\"datetime64[ms]\"), range=(config[\"starttime\"], config[\"endtime\"]), bins=bins, label=f\"Liu et al. (2020): {len(catalog_liu2020['time'])}\")\n",
    "plt.hist(np.array(catalog_baseline[\"time\"]).astype(\"datetime64[ms]\"), range=(config[\"starttime\"], config[\"endtime\"]), bins=bins, alpha=0.6, label=f\"{label_baseline}: {len(catalog_baseline['time'])}\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Date\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.gca().autoscale(enable=True, axis='x', tight=True)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.legend()\n",
    "plt.savefig(root_dir(\"figures/earthquake_number_liu.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(root_dir(\"figures/earthquake_number_liu.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_size = 0.5\n",
    "plt.figure()\n",
    "plt.scatter(np.array(catalog_model[\"time\"]).astype(\"datetime64[ms]\"), catalog_model[\"magnitude\"], s=marker_size, linewidths=marker_size, alpha=1.0, rasterized=True)\n",
    "plt.scatter(np.array(catalog_baseline[\"time\"]).astype(\"datetime64[ms]\"), catalog_baseline[\"magnitude\"], s=marker_size, linewidths=marker_size, alpha=1.0, rasterized=True)\n",
    "plt.xlim(datetime.fromisoformat(config[\"starttime\"]), datetime.fromisoformat(config[\"endtime\"]))\n",
    "# plt.ylim(top=events[\"magnitude\"].max())\n",
    "ylim = plt.ylim(bottom=-1)\n",
    "xlim = plt.xlim()\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.gca().set_prop_cycle(None)\n",
    "plt.plot(datetime.fromisoformat(config[\"starttime\"]), -10, '.', markersize=15, alpha=1.0, label=f\"{label_model}: {len(catalog_model['magnitude'])}\")\n",
    "plt.plot(datetime.fromisoformat(config[\"starttime\"]), -10, '.', markersize=15, alpha=1.0, label=f\"{label_baseline}: {len(catalog_baseline['magnitude'])}\")\n",
    "plt.legend()\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "# plt.grid()\n",
    "plt.savefig(root_dir(\"figures/earthquake_magnitude_time.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(root_dir(\"figures/earthquake_magnitude_time.pdf\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_size = 0.2\n",
    "\n",
    "fig = plt.figure(figsize=plt.rcParams[\"figure.figsize\"]*np.array([0.8,1.1]))\n",
    "box = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "text_loc = [0.05, 0.90]\n",
    "plt.subplot(311)\n",
    "plt.scatter(np.array(catalog_model[\"time\"]).astype(\"datetime64[ms]\"), catalog_model[\"sigma_time\"], s=marker_size, linewidths=marker_size, label=\"Traveltime\", rasterized=True)\n",
    "# plt.ylim([0, 3])\n",
    "plt.ylabel(r\"$\\sigma_{11}$ (s)\")\n",
    "plt.legend(loc=\"upper right\", fontsize=\"small\")\n",
    "plt.text(text_loc[0], text_loc[1], '(i)', horizontalalignment='left', verticalalignment=\"top\", \n",
    "         transform=plt.gca().transAxes, fontweight=\"normal\", bbox=box)\n",
    "plt.xlim(datetime.fromisoformat(config[\"starttime\"]), datetime.fromisoformat(config[\"endtime\"]))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.scatter(np.array(catalog_model[\"time\"]).astype(\"datetime64[ms]\"), catalog_model[\"sigma_amp\"], s=marker_size, linewidths=marker_size, label=\"Amplitude\", rasterized=True)\n",
    "# plt.ylim([0, 1])\n",
    "plt.ylabel(r\"$\\sigma_{22}$ ($\\log_{10}$ m/s)\")\n",
    "plt.legend(loc=\"upper right\", fontsize=\"small\")\n",
    "plt.text(text_loc[0], text_loc[1], '(ii)', horizontalalignment='left', verticalalignment=\"top\", \n",
    "         transform=plt.gca().transAxes, fontweight=\"normal\", bbox=box)\n",
    "plt.xlim(datetime.fromisoformat(config[\"starttime\"]), datetime.fromisoformat(config[\"endtime\"]))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.scatter(np.array(catalog_model[\"time\"]).astype(\"datetime64[ms]\"), catalog_model[\"cov_time_amp\"], s=marker_size, linewidths=marker_size, label=\"Traveltime vs. Amplitude\", rasterized=True)\n",
    "plt.ylabel(r\"$\\Sigma_{12}$\")\n",
    "# plt.ylim([-0.5, 0.5])\n",
    "plt.legend(loc=\"upper right\", fontsize=\"small\")\n",
    "plt.text(text_loc[0], text_loc[1], '(iii)', horizontalalignment='left', verticalalignment=\"top\", \n",
    "         transform=plt.gca().transAxes, fontweight=\"normal\", bbox=box)\n",
    "plt.xlim(datetime.fromisoformat(config[\"starttime\"]), datetime.fromisoformat(config[\"endtime\"]))\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "# plt.suptitle(r\"Covariance Matrix ($\\Sigma$) Coefficients\")\n",
    "plt.tight_layout()\n",
    "plt.gcf().align_labels()\n",
    "plt.savefig(root_dir(\"figures/covariance.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(root_dir(\"figures/covariance.pdf\"), bbox_inches=\"tight\", dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## plot error distribution\n",
    "t_model = t_gamma\n",
    "xyz_model = xyz_gamma\n",
    "t_baseline = t_scsn\n",
    "xyz_baseline = xyz_scsn\n",
    "mag_model = mag_gamma\n",
    "mag_baseline = mag_scsn\n",
    "\n",
    "time_threshold = 5\n",
    "err_time, err_xyz, err_xy, err_z, err_loc, t = calc_time_loc_error(t_model, xyz_model, t_baseline, xyz_baseline, time_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = err_xyz[:,0]\n",
    "y = err_xyz[:,1]\n",
    "z = err_xyz[:,2]\n",
    "\n",
    "# definitions for the axes\n",
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "spacing = 0.01\n",
    "\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_colorbar = [left, bottom - 0.13 - spacing, width, 0.05]\n",
    "rect_histx = [left, bottom + height + spacing, width, 0.2]\n",
    "rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "# start with a rectangular Figure\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "ax_scatter = plt.axes(rect_scatter)\n",
    "ax_colorbar = plt.axes(rect_colorbar)\n",
    "\n",
    "# ax_scatter.tick_params(direction='in', top=True, right=True)\n",
    "ax_histx = plt.axes(rect_histx)\n",
    "ax_histx.tick_params(direction='in', labelbottom=False)\n",
    "ax_histy = plt.axes(rect_histy)\n",
    "ax_histy.tick_params(direction='in', labelleft=False)\n",
    "\n",
    "# the scatter plot:\n",
    "sc = ax_scatter.scatter(x, y, s=0.5, c=t, cmap=\"jet\", alpha=0.3, rasterized=True)\n",
    "ax_scatter.set_xlabel(\"$\\Delta$x (km)\")\n",
    "ax_scatter.set_ylabel(\"$\\Delta$y (km)\")\n",
    "\n",
    "cbar = plt.colorbar(sc, cax=ax_colorbar, orientation=\"horizontal\", ticks=[t[0],  t[-1]])\n",
    "print([str(start_datetime), str(end_datetime)])\n",
    "cbar.ax.set_xticklabels([dates[0], dates[-1]]) \n",
    "\n",
    "# now determine nice limits by hand:\n",
    "binwidth = 0.5\n",
    "lim = 11\n",
    "ax_scatter.set_xlim((-lim, lim))\n",
    "ax_scatter.set_ylim((-lim, lim))\n",
    "\n",
    "bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "ax_histx.hist(x, bins=bins)\n",
    "ax_histy.hist(y, bins=bins, orientation='horizontal')\n",
    "\n",
    "ax_histx.set_xlim(ax_scatter.get_xlim())\n",
    "ax_histy.set_ylim(ax_scatter.get_ylim())\n",
    "ax_histx.set_ylabel(\"Frequency\")\n",
    "ax_histy.set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.savefig(f\"figures/error-xy-{dates[0]}-{dates[-1]}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(f\"figures/error-xy-{dates[0]}-{dates[-1]}.pdf\", bbox_inches=\"tight\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "fig = plt.figure(figsize=plt.rcParams[\"figure.figsize\"]*np.array([1.0,1.3]))\n",
    "plt.subplot(211)\n",
    "plt.hist(x, bins=bins)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim((-lim, lim))\n",
    "plt.gca().set_xlabel([])\n",
    "plt.xlabel(\"$\\Delta$x (km)\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(y, bins=bins)\n",
    "plt.xlim((-lim, lim))\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"$\\Delta$y (km)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"figures/error-xy-{dates[0]}-{dates[-1]}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "# plt.savefig(f\"figures/error-xy-{dates[0]}-{dates[-1]}.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = np.arange(-15, 20 + binwidth, 1.5*binwidth)\n",
    "fig = plt.figure(figsize=plt.rcParams[\"figure.figsize\"]*np.array([1.0,1.3]))\n",
    "plt.subplot(211)\n",
    "plt.hist(z, bins=bins)\n",
    "# plt.hist(z, bins=51, range=(-15, 20))\n",
    "# plt.xlim([0, 20])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"$\\Delta$z (km)\")\n",
    "plt.savefig(f\"figures/error-z-{dates[0]}-{dates[-1]}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(f\"figures/error-z-{dates[0]}-{dates[-1]}.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# bins = np.arange(-3, 3 + 0.15, 0.15)\n",
    "fig = plt.figure(figsize=plt.rcParams[\"figure.figsize\"]*np.array([1.0,0.8]))\n",
    "# plt.subplot(211)\n",
    "plt.hist(err_time, bins=51, range=(-3, 3))\n",
    "plt.xlim([-3, 3])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"$\\Delta$t (s)\")\n",
    "plt.savefig(f\"figures/error-t-{dates[0]}-{dates[-1]}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(f\"figures/error-t-{dates[0]}-{dates[-1]}.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_time, err_mag, t, mag = calc_time_mag_error(t_model, mag_model, t_baseline, mag_baseline, time_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mag\n",
    "y = err_mag\n",
    "\n",
    "# definitions for the axes\n",
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "spacing = 0.01\n",
    "\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "# start with a rectangular Figure\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "ax_scatter = plt.axes(rect_scatter)\n",
    "# ax_colorbar = plt.axes(rect_colorbar)\n",
    "\n",
    "# ax_scatter.tick_params(direction='in', top=True, right=True)\n",
    "ax_histy = plt.axes(rect_histy)\n",
    "ax_histy.tick_params(direction='in', labelleft=False)\n",
    "\n",
    "# the scatter plot:\n",
    "sc = ax_scatter.scatter(x, y, s=2, linewidths=1, alpha=0.3, rasterized=True)\n",
    "ax_scatter.set_xlabel(\"Magnitude (SCSN)\")\n",
    "ax_scatter.set_ylabel(\"$\\Delta$m\")\n",
    "\n",
    "# now determine nice limits by hand:\n",
    "binwidth = 0.1\n",
    "lim = 2\n",
    "ax_scatter.set_ylim((-lim, lim))\n",
    "\n",
    "bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "ax_histy.hist(y, bins=bins, orientation='horizontal')\n",
    "\n",
    "ax_histy.set_ylim(ax_scatter.get_ylim())\n",
    "ax_histy.set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.savefig(f\"figures/error-mag-{dates[0]}-{dates[-1]}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(f\"figures/error-mag-{dates[0]}-{dates[-1]}.pdf\", bbox_inches=\"tight\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (np.abs(err_time) < 3)\n",
    "print(\"Mean\", np.mean(err_time))\n",
    "print(\"STD\", np.std(err_time))\n",
    "print(\"MAE\", np.mean(np.abs(err_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = (np.abs(err_xyz[:,0]) < 10) & (np.abs(err_xyz[:,1]) < 10) & (np.abs(err_xyz[:,2]) < 20)\n",
    "print(\"Mean\", np.mean(err_xyz[idx,0]), np.mean(err_xyz[idx,1]), np.mean(err_xyz[idx,2]))\n",
    "print(\"STD\", np.std(err_xyz[idx,0]), np.std(err_xyz[idx,1]), np.std(err_xyz[idx,2]))\n",
    "print(\"MAE\", np.mean(np.abs(err_xyz[idx,0])), np.mean(np.abs(err_xyz[idx,1])), np.mean(np.abs(err_xyz[idx,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (np.abs(err_mag) < 2)\n",
    "print(\"Mean\", np.mean(err_mag))\n",
    "print(\"STD\", np.std(err_mag))\n",
    "print(\"MAE\", np.mean(np.abs(err_mag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# compare with other catalog\n",
    "time_threshold = 5\n",
    "fp = open(f\"performance-{dates[0]}-{dates[-1]}.txt\", \"w\")\n",
    "recall, precision, f1 = calc_detection_performance(t_model, t_scsn, time_threshold)\n",
    "print(f\"Pred vs. SCSN : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\")\n",
    "fp.write(f\"Pred vs. SCSN : {len(t_model)}, {len(t_scsn)}\\n\")\n",
    "fp.write(f\"Pred vs. SCSN : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\\n\")\n",
    "recall, precision, f1 = calc_detection_performance(t_model, t_shelly2020, time_threshold)\n",
    "print(f\"Pred vs. Shelly (2020) : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\")\n",
    "fp.write(f\"Pred vs. Shelly (2020) : {len(t_model)}, {len(t_shelly2020)}\\n\")\n",
    "fp.write(f\"Pred vs. Shelly (2020) : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\\n\")\n",
    "recall, precision, f1 = calc_detection_performance(t_model, t_liu2020, time_threshold)\n",
    "print(f\"Pred vs. Ming (2020) : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\")\n",
    "fp.write(f\"Pred vs. Ming (2020) : {len(t_model)}, {len(t_liu2020)}\\n\")\n",
    "fp.write(f\"Pred vs. Ming (2020) : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\\n\")\n",
    "recall, precision, f1 = calc_detection_performance(t_model, t_ross2019, time_threshold)\n",
    "print(f\"Pred vs. Zachary (2019) : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\")\n",
    "fp.write(f\"Pred vs. Zachary (2019) : {len(t_model)}, {len(t_ross2019)}\\n\")\n",
    "fp.write(f\"Pred vs. Zachary (2019) : recall={recall:.3f}, precision={precision:.3f}, f1={f1:.3f}\\n\")\n",
    "fp.write(f\"=======================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"P-picks: {len(picks[(picks['type']=='p')])}\")\n",
    "print(f\"S-picks: {len(picks[(picks['type']=='s')])}\")\n",
    "print(f\"Associated P-picks: {len(picks[(picks['type']=='p') & (picks['event_idx']!=-1)])}\")\n",
    "print(f\"Associated S-picks: {len(picks[(picks['type']=='s') & (picks['event_idx']!=-1)])}\")\n",
    "print(f\"Unassociated P-picks: {len(picks[(picks['type']=='p')]) - len(picks[(picks['type']=='p') & (picks['event_idx']!=-1)])}\")\n",
    "print(f\"Unassociated S-picks: {len(picks[(picks['type']=='s')]) - len(picks[(picks['type']=='s') & (picks['event_idx']!=-1)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.fromisoformat(\"2019-07-07T23:59:58\")\n",
    "endtime = datetime.fromisoformat(\"2019-07-08T00:06:02\")\n",
    "\n",
    "selected_picks = picks[ (picks[\"time\"] > starttime) & (picks[\"time\"] < endtime) ]\n",
    "selected_picks_full = pd.merge(left=selected_picks, right=stations, left_on=\"id\", right_on=\"station\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_gamma = catalog_gamma[ (catalog_gamma[\"time\"] > starttime) & (catalog_gamma[\"time\"] < endtime) ]\n",
    "selected_scsn = catalog_scsn[ (catalog_scsn[\"time\"] > starttime) & (catalog_scsn[\"time\"] < endtime) ]\n",
    "selected_ross2019 = catalog_ross2019[ (catalog_ross2019[\"time\"] > starttime) & (catalog_ross2019[\"time\"] < endtime) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6))\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(12, 6))\n",
    "\n",
    "color = {}\n",
    "selected_gamma = selected_gamma.sort_values(by=\"time\")\n",
    "for i, x in enumerate(selected_gamma[\"event_idx\"]):\n",
    "    color[x] = f\"C{i}\"\n",
    "for i, x in enumerate(selected_picks_full[\"event_idx\"]):\n",
    "    if x not in color:\n",
    "        color[x] = \"k\"\n",
    "\n",
    "# plt.subplot(2, 1, 1)\n",
    "ax[0].scatter(selected_picks_full[\"time\"], selected_picks_full[\"latitude\"], s=8, c=[color[x] for x in selected_picks_full[\"event_idx\"]], linewidths=1, alpha=1.0)\n",
    "ax[0].scatter(selected_gamma[\"time\"], selected_gamma[\"latitude\"], s=150, c=[color[x] for x in selected_gamma[\"event_idx\"]], marker=\"+\", linewidths=4, alpha=1.0, label=f\"GaMMA: {len(selected_gamma['time'])}\")\n",
    "ax[0].scatter(selected_ross2019[\"time\"], selected_ross2019[\"latitude\"], s=120, edgecolors=\"k\", facecolors=\"none\", marker=\"o\", linewidths=1, alpha=1.0, label=f\"Ross et al. (2019): {len(selected_ross2019['time'])}\")\n",
    "ax[0].scatter(selected_scsn[\"time\"], selected_scsn[\"latitude\"], s=120, edgecolors=\"b\", facecolors=\"none\", marker=\"o\", linewidths=2,  alpha=1.0, label=f\"SCSN: {len(selected_scsn['time'])}\")\n",
    "ax[0].autoscale(enable=True, axis='x', tight=True)\n",
    "# plt.gca().set_xticklabels([])\n",
    "ax[0].set_ylabel(\"Latitude\")\n",
    "ax[0].legend(bbox_to_anchor=(0.35, 0), loc='lower left', ncol=1)\n",
    "# plt.subplot(2, 1, 2)\n",
    "ax[1].scatter(selected_picks_full[\"time\"], selected_picks_full[\"longitude\"], s=8, c=[color[x] for x in selected_picks_full[\"event_idx\"]], linewidths=1, alpha=1.0)\n",
    "ax[1].scatter(selected_gamma[\"time\"], selected_gamma[\"longitude\"], s=120, c=[color[x] for x in selected_gamma[\"event_idx\"]], marker=\"+\", linewidths=3, alpha=1.0, label=f\"GaMMA:{len(selected_gamma['time'])}\")\n",
    "ax[1].scatter(selected_ross2019[\"time\"], selected_ross2019[\"longitude\"], s=120, edgecolors=\"k\", facecolors=\"none\", marker=\"o\", linewidths=1, alpha=1.0, label=f\"Ross et al. (2019):{len(selected_ross2019['time'])}\")\n",
    "ax[1].scatter(selected_scsn[\"time\"], selected_scsn[\"longitude\"], s=120, edgecolors=\"b\", facecolors=\"none\", marker=\"o\", linewidths=2, alpha=1.0, label=f\"SCSN: {len(selected_scsn['time'])}\")\n",
    "ax[1].set_ylabel(\"Longitude\")\n",
    "ax[1].autoscale(enable=True, axis='x', tight=True)\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%m-%dT%H:%M'))\n",
    "fig.autofmt_xdate()\n",
    "fig.tight_layout()\n",
    "# plt.legend()\n",
    "\n",
    "fig.savefig(\"figures/example.png\", bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(\"figures/example.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = selected_gamma[\"time\"].to_numpy().astype(np.float64)/1e9\n",
    "t_baseline = selected_ross2019[\"time\"].to_numpy().astype(np.float64)/1e9\n",
    "diff = (t_model[:, np.newaxis] - t_baseline[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = selected_gamma.iloc[~np.any(np.abs(diff) < 4, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = Client(config[\"client\"]).get_stations(\n",
    "    network=\",\".join(config[\"networks\"]),\n",
    "    station=\"*\",\n",
    "    starttime=config[\"starttime\"],\n",
    "    endtime=config[\"endtime\"],\n",
    "    minlongitude=config[\"xlim_degree\"][0],\n",
    "    maxlongitude=config[\"xlim_degree\"][1],\n",
    "    minlatitude=config[\"ylim_degree\"][0],\n",
    "    maxlatitude=config[\"ylim_degree\"][1],\n",
    "    channel=config[\"channels\"],\n",
    "    # channel=\"HNZ\",\n",
    "    level=\"response\",\n",
    ")  # ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_stations = [\"LRL\", \"SLA\", \"Q0072\"]\n",
    "# exclude_stations = [\"Q0072\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_locs = defaultdict(dict)\n",
    "for network in stations:\n",
    "    for station in network:\n",
    "        for chn in station:\n",
    "            if station.code in exclude_stations:\n",
    "                continue\n",
    "            sid = f\"{network.code}.{station.code}.{chn.location_code}.{chn.code[:-1]}\"\n",
    "            if sid in station_locs:\n",
    "                station_locs[sid][\"component\"] += f\",{chn.code[-1]}\"\n",
    "                station_locs[sid][\"response\"] += f\",{chn.response.instrument_sensitivity.value:.2f}\"\n",
    "            else:\n",
    "                component = f\"{chn.code[-1]}\"\n",
    "                response = f\"{chn.response.instrument_sensitivity.value:.2f}\"\n",
    "                dtype = chn.response.instrument_sensitivity.input_units.lower()\n",
    "                tmp_dict = {}\n",
    "                tmp_dict[\"longitude\"], tmp_dict[\"latitude\"], tmp_dict[\"elevation(m)\"] = (\n",
    "                    chn.longitude,\n",
    "                    chn.latitude,\n",
    "                    chn.elevation,\n",
    "                )\n",
    "                tmp_dict[\"component\"], tmp_dict[\"response\"], tmp_dict[\"unit\"] = component, response, dtype\n",
    "                station_locs[sid] = tmp_dict\n",
    "\n",
    "station_locs = pd.DataFrame.from_dict(station_locs, orient='index')\n",
    "# station_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stream(stream, event, stations, picks, degree2km=111.19492474777779, sampling_rate=100):\n",
    "    \n",
    "    # plt.figure(figsize=(6, 3))\n",
    "    plt.figure()\n",
    "\n",
    "    event_lng, event_lat, event_dep = event[\"longitude\"], event[\"latitude\"], event[\"depth(m)\"]/1e3\n",
    "    picks[\"id2\"] = picks[\"id\"].apply(lambda x: x[:-2])\n",
    "\n",
    "    dists = []\n",
    "    vecs = []\n",
    "    ids = []\n",
    "    starttimes = []\n",
    "    \n",
    "    nt = len(stream[0].data) - 1\n",
    "    # nt0 = 0\n",
    "    for trace in stream:\n",
    "        if trace.id[-3:] != \"HHZ\":\n",
    "        # if trace.id[-1:] != \"Z\":\n",
    "            continue\n",
    "        if trace.id[:-1] not in stations.index:\n",
    "            continue\n",
    "        sta_lng, sta_lat, sta_elv = stations.loc[trace.id[:-1]][\"longitude\"], stations.loc[trace.id[:-1]][\"latitude\"], -stations.loc[trace.id[:-1]][\"elevation(m)\"]/1e3\n",
    "        dist = np.sqrt(((event_lng - sta_lng)*degree2km)**2 + ((event_lat - sta_lat)*degree2km)**2 + (event_dep - sta_elv)**2) \n",
    "        dists.append(dist)\n",
    "        vecs.append(trace.data[:nt])\n",
    "        ids.append(trace.id)\n",
    "        starttimes.append(trace.stats.starttime.datetime)\n",
    "    nt0 = int((min(dists)/6.0-0.5)*sampling_rate)\n",
    "    print(nt0)\n",
    "    vecs = np.array(vecs)\n",
    "    print(vecs.shape)\n",
    "    vecs = vecs[:, nt0:nt0+int(8.5*sampling_rate)]\n",
    "    vecs = vecs/np.std(vecs)/7\n",
    "    dists = np.array(dists)\n",
    "    # vecs = vecs/np.std(vecs, axis=1, keepdim=True)\n",
    "    \n",
    "    normalize = lambda x: (x - np.mean(x)) / np.std(x)\n",
    "    num_picks = 0\n",
    "    start_plot = False\n",
    "    ii = 0\n",
    "    for i, idx in enumerate(np.argsort(dists)):\n",
    "        t0 = starttimes[idx]\n",
    "        t1 = starttimes[idx] + timedelta(seconds=vecs.shape[1]/sampling_rate+ 10)\n",
    "        t = [t0 + timedelta(seconds=(x+nt0)/sampling_rate) for x in np.arange(0, len(vecs[idx]))]\n",
    "\n",
    "        # pick_ = picks[(picks[\"event_idx\"] == event[\"event_idx\"]) & (picks[\"id\"] == ids[idx][:-1]) & (picks[\"time\"] > t0) & (picks[\"time\"] < t1)]\n",
    "        pick_ = picks[(picks[\"event_idx\"] == event[\"event_idx\"]) & (picks[\"id2\"] == ids[idx][:-3]) & (picks[\"time\"] > t0) & (picks[\"time\"] < t1)]\n",
    "        num_picks += len(pick_)\n",
    "        if  (len(pick_) > 0) or (i >= 2):\n",
    "            start_plot = True\n",
    "        if not start_plot:\n",
    "            continue\n",
    "        \n",
    "        plt.plot(t, vecs[idx] + ii + 1, 'k', linewidth=0.5, rasterized=True)\n",
    "\n",
    "        if len(pick_[pick_[\"type\"] == \"p\"]) > 0:\n",
    "            p = pick_[pick_[\"type\"] == \"p\"][\"time\"].median()\n",
    "            plt.plot([p, p], [ii+1-0.8, ii+1+0.8], 'b', linewidth=2.5)\n",
    "        if len(pick_[pick_[\"type\"] == \"s\"]) > 0:\n",
    "            s = pick_[pick_[\"type\"] == \"s\"][\"time\"].median()\n",
    "            plt.plot([s, s], [ii+1-0.8, ii+1+0.8], 'r', linewidth=2.5)\n",
    "        # for k in range(len(pick_)):\n",
    "        #     if pick_.iloc[k][\"type\"] == \"p\":\n",
    "        #         plt.plot([pick_.iloc[k][\"time\"], pick_.iloc[k][\"time\"]], [ii+1-0.5, ii+1+0.5], 'b', linewidth=1.5)\n",
    "        #     if pick_.iloc[k][\"type\"] == \"s\":\n",
    "        #         plt.plot([pick_.iloc[k][\"time\"], pick_.iloc[k][\"time\"]], [ii+1-0.5, ii+1+0.5], 'r', linewidth=1.5)\n",
    "\n",
    "        # if ii > 20:\n",
    "        #     break\n",
    "        ii += 1\n",
    "\n",
    "    print(f\"{num_picks = }\")\n",
    "    plt.yticks(range(0, 11, 2), range(0, 11, 2))\n",
    "    plt.ylim([0, 10.9])\n",
    "\n",
    "    plt.gca().autoscale(enable=True, axis='x', tight=True)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%M:%S'))\n",
    "    plt.gcf().autofmt_xdate()   \n",
    "    plt.xlim([t[0], t[-1]])\n",
    "    plt.ylabel(\"Station index by distance\")\n",
    "    plt.xlabel(\"Time from 2019-07-08T00\")\n",
    "   \n",
    "    plt.title(f\"M = {event['magnitude']:.1f}, \"+ r\"$\\sigma_{11}$ = \" + f\"{event['sigma_time']:.1f}\" + r' (s)' + ', ' +  r'$\\sigma_{22}$ = ' + f\"{event['sigma_amp']:.1f}\" + r' ($\\log_{10}$ m/s)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/new_events/{event[0]}.jpg\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"figures/new_events/{event[0]}.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "event = new_events.iloc[-1]\n",
    "# plot_stream(stream, event, station_locs, selected_picks_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 20\n",
    "client = Client(config[\"client\"])\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "for index, event in new_events.iterrows():\n",
    "    starttime = obspy.UTCDateTime(event[\"time\"]) #+ event[\"depth(m)\"] / 1000 / 7\n",
    "    endtime = starttime + interval\n",
    "    fname = \"{}.mseed\".format(event[\"time\"].isoformat())\n",
    "\n",
    "    if os.path.exists(f\"data/{fname}\"):\n",
    "        stream = obspy.read(f\"data/{fname}\")\n",
    "        # stream = stream.filter(\"highpass\", freq=1.0)\n",
    "        plot_stream(stream, event, station_locs, selected_picks_full)\n",
    "        # break\n",
    "        continue\n",
    "\n",
    "    max_retry = 10\n",
    "    stream = obspy.Stream()\n",
    "    print(f\"{fname} download starts\")\n",
    "    for network in stations:\n",
    "        for station in network:\n",
    "            if station.code in exclude_stations:\n",
    "                continue\n",
    "            print(f\"********{network.code}.{station.code}********\")\n",
    "            retry = 0\n",
    "            while retry < max_retry:\n",
    "                try:\n",
    "                    tmp = client.get_waveforms(\n",
    "                        network.code,\n",
    "                        station.code,\n",
    "                        \"*\",\n",
    "                        config[\"channels\"],\n",
    "                        starttime,\n",
    "                        endtime,\n",
    "                        attach_response=True,\n",
    "                    )\n",
    "                    for trace in tmp:\n",
    "                        if trace.stats.sampling_rate != 100:\n",
    "                            trace = trace.interpolate(100, method=\"linear\")\n",
    "                        # trace = trace.detrend(\"spline\", order=2, dspline=5*trace.stats.sampling_rate)\n",
    "                        stream.append(trace)\n",
    "                    stream += tmp\n",
    "                    break\n",
    "                except Exception as err:\n",
    "                    print(\"Error {}.{}: {}\".format(network.code, station.code, err))\n",
    "                    message = \"No data available for request.\"\n",
    "                    if str(err)[: len(message)] == message:\n",
    "                        break\n",
    "                    retry += 1\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "            if retry == max_retry:\n",
    "                print(\n",
    "                    f\"{fname}: MAX {max_retry} retries reached : {network.code}.{station.code}\"\n",
    "                )\n",
    "\n",
    "    stream = stream.merge()\n",
    "    stream = stream.trim(starttime, endtime)\n",
    "    stream = stream.remove_sensitivity()\n",
    "    stream = stream.detrend(\n",
    "        \"spline\", order=2, dspline=1 * stream[0].stats.sampling_rate\n",
    "    )\n",
    "    # stream = stream.filter(\"highpass\", freq=1.0)\n",
    "    stream.write(f\"data/{fname}\", format=\"MSEED\")\n",
    "\n",
    "    plot_stream(stream, event, station_locs, selected_picks_full)\n",
    "    plt.show()\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4d5179fc222eb76bfd3dcff5bf88b43751287e77ddc0be170fe093e3076340e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
